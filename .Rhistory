installed.packages('plotly')
install.packages('plotly')
install.packages('ggplot2')
install.packages('plotly')
library(ggplot2)
library(plotly)
pl<-ggplot(mtcars,aes(mpg,wt))+geom_point()
mpl<-ggplotly(pl)
mpl
print(mpl)
mpl<-ggplotly(mpl,p=ggplot2::last_plot())
pl<-ggplot(mtcars,aes(mpg,wt))+geom_point()
pl<-ggplot2(mtcars,aes(mpg,wt))+geom_point()
library(ggplot2)
library(plotly)
pl<-ggplot(mtcars,aes(mpg,wt))+geom_point()
print(pl)
mpl<-ggplotly(pl)
print(mpl)
mpl<- plot_ly(x=~pl,
type='histogram',
color=~code,
frame=~frame,
alpha=0.7)
print(mpl)
library(dplyr)
a<-mtcars
summary(a)
mtcars$rv<-mtcars$hp+mtcars$gear
mtcars
drop(mtcars$rv)
drop(mtcars$rv,)
drop(mtcars$rv)
mtcars
col(mtcars$rv)
col(-mtcars$rv)
col(drop(mtcars$rv))
a<-mtcars
summary(a0)
summary(a)
a$rv<-a$hp+a$gear
a
a<-subset(a,select = -c(rv))
a
height<-c(5.1,5.6,5.8,5.3,5.9,6.1)
height
weight<-c(55,62,61,58,65,54)
weight
data<-c(height,weight)
data
data<-as.data.frame(data)
adta
data
rm(data)
data<c(colnames(height)=height,colnames(weight)=weight)
model<-lm(weight~height)
summary(model)
a<-data.frame(x=6.3)
res<-predict(model,a)
res
rm(a,model)
rm(.)
rm(,)
x=c(5.2,5.9,5.7,5.6,5.5)
x
y=c(55,59,61,62,52)
y
model=lm(y~x)
a<-data.frame(x=6.1)
result<-predict(model,a)
result
result<-predict.lm(model,a)
result
rm(A)
rm(a,model)
a<-cars
View(a)
View(a)
View(a)
View(a)
carsmodel<-lm(dist~speed,a)
b1<-data.frame(speed=23)
result<-predict.lm(carsmodel,b1)
result
setwd("L:/ML with R/Decision Tree & Random Forest")
install.packages('rpart')
library(rpart)
help(rpart)
str(kyphosis)
data<-read.csv(kyphosis)
data<-data.frame(kyphosis)
View(data)
tree<-rpart(data~.,method = 'class',data=data)
tree<-rpart(kyphosis~.,method = 'class',data=kyphosis)
tree<-rpart(kyphosis~.,method ='class',data=kyphosis)
printcp(tree)
##Read data
str(kyphosis)
head(kyphosis)
tree<-rpart(kyphosis ~.,method ='class',data=kyphosis)
data_tree<-data.frame(kyphosis)
tree<-rpart(data_tree ~.,method ='class',data=data_tree)
##Read data
data_tree<-read.csv('kyphosis.csv')
tree<-rpart(data_tree ~.,method ='class',data=data_tree)
help(rpart)
setwd("L:/ML with R/Tree Method")
library(ISLR)
data<-read.csv(College)
head(College)
df<-data.frame(College)
View(df)
#Scatterplot of Grad.Rate versus Room.Board, colored by the Private column
library(ggplot2)
pl<-ggplot(df,aes(Grad.Rate,Room.Board))+geom_point(aes(fill=Private ))
print(pl)
pl<-ggplot(df,aes(Grad.Rate,Room.Board))+geom_point(aes(color=Private ))
print(pl)
##histogram of full time undergrad students, color by Private
pl2<-ggplot(df,aes(F.Undergrad))+geom_histogram(aes(color=ptivate))
print(pl2)
##histogram of full time undergrad students, color by Private
pl2<-ggplot(df,aes(F.Undergrad))+geom_histogram(aes(color=private))
print(pl2)
##histogram of full time undergrad students, color by Private
pl2<-ggplot(df,aes(F.Undergrad))+geom_histogram(aes(color=Private))
print(pl2)
##histogram of full time undergrad students, color by Private
pl2<-ggplot(df,aes(F.Undergrad))+geom_histogram(aes(fill=Private))
print(pl2)
##histogram of full time undergrad students, color by Private
pl2<-ggplot(df,aes(F.Undergrad))+geom_histogram(aes(fill=Private),bins = 30)
print(pl2)
##histogram of full time undergrad students, color by Private
pl2<-ggplot(df,aes(F.Undergrad))+geom_histogram(aes(fill=Private),bins = 50,color='black')
print(pl2)
## histogram of Grad.Rate colored by Private
pl3<-ggplot(df,aes(Grad.Rate))+geom_histogram(aes(fill=Private),bins = 50,color='black')
print(pl3)
View(df)
a<-df$Grad.Rate==100
a<-subset(df,Grad.Rate>100)
a
a
print(a)
View(a)
a$Grad.Rate<-100
View(a)
df['Cazenovia College','Grad.Rate']<-100
##Train Test Split
library(caTools)
set.seed(101)
sample = sample.split(df$Private, SplitRatio = .70)
train = subset(df, sample == TRUE)
test = subset(df, sample == FALSE)
#Model
library(rpart)
tree<-rpart(Private~.,method = 'class',data = train)
tree.preds <- predict(tree,test)
head(tree.preds)
tree.preds<-as.data.frame(tree.preds)
joiner<-function(x)
{
if (x>=0.5)
{
return('YES')
}
else
{
return('NO')
}
}
View(tree.preds)
tree.preds$Private<-sapply(tree.preds$Yes,joiner)
head(tree.preds)
table(tree.preds$Private,test$Private)
prp(tree)
library(rpart.plot)
install.packages('rpart.plot')
library(rpart.plot)
prp(tree)
##Random Forest Model
install.packages('randomForest')
library(randomForest)
rf.model<-randomForest(Private~.,data = train,importance=T)
rf.model$confusion
rf.model$importance
rf.preds<-predict(rf.model,test)
table(rf.preds.test$Private)
rf.preds<-predict(rf.model,test)
rf.preds<-predict(rf.model,test)
table(rf.preds,test$Private)
